{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytrends\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pytrends Package\n",
    "# props: https://github.com/GeneralMills/pytrends\n",
    "from pytrends.request import TrendReq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the file\n",
    "dir = \"C:\\\\Users\\\\Saurabh\\\\Downloads\\\\\"\n",
    "source_file = pd.read_excel(dir + \"companies_saurabh.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just some preprocessing\n",
    "source_file.rename(columns = {\n",
    "    'IPO_DATE_TRUE':'Date'}, inplace=True)\n",
    "source_file= source_file.drop(columns=['Stock Symbol'])\n",
    "#len(source_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Organization Name       Date  Year Month Day\n",
      "0           Twitter 2013-11-09  2013    11  09\n",
      "1            Square 2015-11-21  2015    11  21\n",
      "2          Facebook 2012-05-20  2012    05  20\n",
      "3        ServiceNow 2012-07-22  2012    07  22\n",
      "4           Shopify 2015-05-23  2015    05  23\n"
     ]
    }
   ],
   "source": [
    "source_file['Date'] = pd.to_datetime(source_file['Date'], format='%Y-%m-%d')\n",
    "source_file['Year'] = source_file['Date'].apply(lambda x:x.strftime('%Y'))\n",
    "source_file['Month'] = source_file['Date'].apply(lambda x:x.strftime('%m'))\n",
    "source_file['Day'] = source_file['Date'].apply(lambda x:x.strftime('%d'))\n",
    "print(source_file.head(5))\n",
    "#Getting Google Trend values in col\n",
    "source_file['Year_before_IPO'] = 0\n",
    "source_file['Month_before_IPO'] = 0\n",
    "source_file['Day_before_IPO'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Organization Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Year_before_IPO</th>\n",
       "      <th>Month_before_IPO</th>\n",
       "      <th>Day_before_IPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>Passage Bio</td>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>2020</td>\n",
       "      <td>02</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Organization Name       Date  Year Month Day  Year_before_IPO  \\\n",
       "450       Passage Bio 2020-02-29  2020    02  29                0   \n",
       "\n",
       "     Month_before_IPO  Day_before_IPO  \n",
       "450                 0               0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_file[(source_file.Day == '29') & (source_file.Month == '02')] # Checking for leap year Feb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Organization Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Year_before_IPO</th>\n",
       "      <th>Month_before_IPO</th>\n",
       "      <th>Day_before_IPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Organization Name, Date, Year, Month, Day, Year_before_IPO, Month_before_IPO, Day_before_IPO]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_file[(source_file.Day == '1') & (source_file.Month == '03')] # Checking for leap year months prior to that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proxy error. Changing IP\n"
     ]
    }
   ],
   "source": [
    "kw_list = [i for i in source_file['Organization Name']][:10]\n",
    "\n",
    "j = 0                                    # For Initilazing first time with data to df and get indices\n",
    "\n",
    "not_data = []                            # List for not having any companies data \n",
    "\n",
    "for i in kw_list:                       \n",
    "    \n",
    "    # try and catch block introduced to catch the error and get the list of companies\n",
    "    try:\n",
    "        pytrend = TrendReq(hl='en-US',tz=360, timeout=(10,25), proxies=['https://34.203.233.13:80',], retries=2, backoff_factor=0.1)\n",
    "\n",
    "        #pytrend.build_payload(kw_list = [i])       # Build Payloads\n",
    "        \n",
    "        day,month,year = int(source_file.Day[j]),int(source_file.Month[j]),int(source_file.Year[j]) #intitialising day month and year\n",
    "\n",
    "        \n",
    "        # Checking for consistency as there could be leap year with 29 days in Feb\n",
    "        if day == 29 and year == 2016:\n",
    "            day_old = 28\n",
    "            \n",
    "        else:\n",
    "             day_old = day\n",
    "            \n",
    "        \n",
    "        # Year Before IPO let's check the trends\n",
    "        year_before_IPO = pytrend.get_historical_interest([i], year_start=year - 1,\n",
    "                                         month_start=month, day_start=day_old, year_end=year,\n",
    "                                         month_end=month, day_end=day,\n",
    "                                         cat=0, geo='', gprop='', sleep=0)      # Build Payloads\n",
    "        source_file['year_before_IPO'][j] = np.mean(year_before_IPO['' + i])\n",
    "        \n",
    "        \n",
    "        if month == 1:\n",
    "            month_old = 12\n",
    "            year_old = year - 1\n",
    "        \n",
    "        else:\n",
    "            month_old = month - 1 \n",
    "            year_old = year\n",
    "        \n",
    "        # If it's march saves the leap year\n",
    "        if day == 31 and month == 3:\n",
    "            day_old = 28\n",
    "            \n",
    "        else:\n",
    "             day_old = day\n",
    "                \n",
    "        # Month Before IPO let's check the trends \n",
    "        month_before_IPO = pytrend.get_historical_interest([i], year_start=year_old,\n",
    "                                         month_start=month_old, day_start=day_old, year_end=year,\n",
    "                                         month_end=month, day_end=day,\n",
    "                                         cat=0, geo='', gprop='', sleep=0)      # Build Payloads\n",
    "        source_file['month_before_IPO'][j] = np.mean(month_before_IPO['' + i])\n",
    "        \n",
    "        \n",
    "        if day == 1:\n",
    "            day_old = 30\n",
    "            \n",
    "        else:\n",
    "            day_old = day - 1\n",
    "        # Day Before IPO let's check the trends \n",
    "        day_before_IPO = pytrend.get_historical_interest([i], year_start=year,\n",
    "                                         month_start=month, day_start=day_old, year_end=year,\n",
    "                                         month_end=month, day_end=day,\n",
    "                                         cat=0, geo='', gprop='', sleep=0)      # Build Payloads\n",
    "        source_file['day_before_IPO'][j] = np.mean(day_before_IPO['' + i])\n",
    "\n",
    "        j = j + 1\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        print(\"Not Possible for %s company\"%i)\n",
    "        not_data.append(i)                     # Appending if not possible and continue\n",
    "        j = j + 1\n",
    "        \n",
    "        \n",
    "    if(j % 10 == 100):\n",
    "        print(\"Done for %d companies and %d companies are not there in list\"%(j,len(not_data)))\n",
    "        continue\n",
    "        \n",
    "print(\"Done for all\")        \n",
    "print(\"Done for %d companies and %d companies are not there in list\"%(j,len(not_data)))        \n",
    "print(source_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_file.to_csv(dir + 'Google_Trend_Companies.csv', encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Redundant API Dumps\n",
    "dir = \"C:\\\\Users\\\\Saurabh\\\\Desktop\\\\\"\n",
    "\n",
    "def Google_Trend_API(kw_list,dir):\n",
    "    \"\"\"\n",
    "    This Function takes a list and directory as input for finding the trend data from Google weekly for last 5 years\n",
    "    \n",
    "    Input : Input to the function is list of companies  and directory to store  API\n",
    "    \n",
    "    Output: Output of the funtion is .csv file of companies and a list whose data couldn't be extracted\n",
    "    \n",
    "    \"\"\"\n",
    "    from pytrends.request import TrendReq    # Importing Libraries\n",
    "\n",
    "    i = 0                                    # For Initilazing first time\n",
    "    \n",
    "    df = pd.DataFrame()                      # For Storing the values\n",
    "    \n",
    "    not_data = []                            # List for not having any companies data \n",
    "    \n",
    "    for i in kw_list:                              # For Initializing the list\n",
    "        \n",
    "    # try and catch block introduced to catch the error and get the list of companies\n",
    "        try:\n",
    "            pytrend = TrendReq(hl='en-US', timeframe='all',tz=360)\n",
    "\n",
    "            pytrend.build_payload(kw_list = [i])       # Build Payloads\n",
    "\n",
    "            data = pytrend.interest_over_time()  # Generates the data\n",
    "\n",
    "            # Storing in dataframe\n",
    "            df['' + i] = data[i]\n",
    "            #print(df)\n",
    "\n",
    "\n",
    "        except:\n",
    "            print(\"Not Possible for %s company\"%i)\n",
    "            not_data.append(i)                     # Appending if not possible and continue\n",
    "            continue\n",
    "\n",
    "    print(\"Could not get data for following list of companies:\")\n",
    "    print(not_data)\n",
    "\n",
    "        # Storing to csv file\n",
    "    df.to_csv(dir + 'Google_Trend_Company.csv', encoding='utf_8_sig')\n",
    "\n",
    "    return not_data\n",
    "\n",
    "# User list to be defined\n",
    "kw_list = ['Despegar', 'MercadoLibre', 'Grupo Netshoes', 'Azul SA',\n",
    "       'Stone Pagamentos SA', 'Arco Educacao', 'Canacol Energy',\n",
    "       'IRSA Propiedades Comerciales', 'Sienna Biopharmaceuticals',\n",
    "       'Kior', 'Harpoon Therapeutics', 'ARYx Therapeutics',\n",
    "       'WPCS International', 'Kips Bay Medical', 'Intertainment Media',\n",
    "       'Sonus Networks', 'Stratos Lightwave',\n",
    "       'Advanced Life Sciences Holdings', 'InterVideo', 'StorageNetworks',\n",
    "       'Anesiva', 'Helicos BioSciences', 'Evergreen Solar', 'eMachines',\n",
    "       'Penson Worldwide', 'iBEAM Broadcasting',\n",
    "       'Transcept Pharmaceuticals', 'Soapstone Networks',\n",
    "       'Crude Carriers Corp.', 'MaSpaces', 'Novartis', 'Delivery Hero',\n",
    "       'Partners Group', 'Spotify', 'Farfetch', 'HelloFresh',\n",
    "       'Funding Circle', 'Mail.Ru Group', 'Draper Esprit', 'Takeaway.com',\n",
    "       'Rocket Internet', 'Storytel', 'Mimecast', 'IP Group Plc',\n",
    "       'Immotion Group plc', 'trivago', 'Stillfront Group',\n",
    "       'Marley Spoon', 'FunCom', 'Abcam']\n",
    "\n",
    "# Please give directory\n",
    "d = \"C:\\\\Users\\\\Saurabh\\\\Desktop\\\\\"\n",
    "\n",
    "no_company = Google_Trend_API(kw_list,d)\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
