{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "924ed035a207bf4f010dcdda12460b50",
     "grade": false,
     "grade_id": "cell-99e0bc0a673830ab",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "<img src=\"logo-2020.png\" alt=\"frankfurt school hmi\" style=\"width: 160px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c87a2e3c9f856ca7018a64da2a90392f",
     "grade": false,
     "grade_id": "cell-8e6a05f10785a63d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "# Assignment 2.1 Logistic Regression  (14 points total)\n",
    "\n",
    "## Instructions\n",
    "\n",
    "The graded portion of Assignment 2 consists of one notebook:\n",
    "\n",
    "    ps2_nb1-ml.ipynb\n",
    "\n",
    "There is also an ungraded tutorial that is recommended:\n",
    "\n",
    "    2-pandas_introduction.ipynb\n",
    "\n",
    "As before, each notebook is designed for cells to be run sequentially.   \n",
    "\n",
    "### Due Dates\n",
    "\n",
    "- <b>Group M</b> 01.03.2019 before 23:59:59 (CET) <br>\n",
    "- <b>Group D</b> 26.02.2019 before 23:59:59 (CET) \n",
    "\n",
    "NB: Machine Learning I is in Group D.\n",
    "\n",
    "### Instructor\n",
    "* Prof. Dr. Gregory Wheeler ([g.wheeler@fs.de](mailto:g.wheeler@fs.de))\n",
    "\n",
    "---\n",
    "### Declare your collaborators\n",
    "You may work alone or in a group. The maximum group size is 4 people. \n",
    "\n",
    "If you work in a group, use the next cell to enter the list of names (first, last) of your collaborators. \n",
    "~~~python\n",
    "# Example\n",
    "COLLABORATORS = ['Stu Dent', 'May Bee', 'Ki Val Storr']\n",
    "~~~\n",
    "You should also familiarize yourself with the collaboration policy on the course Canvas page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be sure your names are strings\n",
    "COLLABORATORS = ['Gaurav Sharma']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5ecf973376e556895de86423e6c46680",
     "grade": false,
     "grade_id": "cell-bd11f75c0e54637c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Logistic Regression with Two Features\n",
    "\n",
    "Suppose your task is to predict the solvency of a firm based on two financial indicators: the firm's <i>return on equity</i> and the firm's <i>current ratio</i>.  <b>Return on Equity</b> (ROE) is a financial indicator which measures how much profit a firm generates with the equity invested by its shareholders. A positive value is good, whereas a negative value is bad. <b>Current ratio</b> is a liquidity measure that measures the firm's ability to pay near-term financial obligations.  A negative value may indicate that net working capital is negative, whereas positive values are good.\n",
    "\n",
    "### Your Task\n",
    "\n",
    "  - <b>Part A</b>: Your task is to build a logistic regression classification model that estimates the probability that a firm is <b>insolvent</b> ($y = 1$) or <b>solvent</b> ($y=0$) based on the features <b>ROE</b> and <b>Current Ratio</b>.  The (artificial) data set you are working with has unusually high variance in both ROE and current ratio, approximating what one might find for young technology firms or start ups. That said, don't get hung up on the cover story for this data set.  \n",
    "\n",
    "* <b>Part B</b>: Use the Sklearn to build a logistic regression classifier to perform some analysis.\n",
    "\n",
    "To begin, run the next cell to import libraries you will need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PART A - Build a Logistic Regression Classifier\n",
    "\n",
    "## I. Data preparation \n",
    "\n",
    "Start by inspecting the dataset `ps2_data-1.csv` in the data folder.  Notice that if you try to load this data as a numpy array, using for example\n",
    "~~~python\n",
    "\n",
    "data = np.loadtxt('ps2_data-1.csv', delimiter = ',')\n",
    "\n",
    "~~~\n",
    "\n",
    "you will see an error.  Why? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('ps2_data-1.csv', delimiter = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6fa26f4a800ea88239609650389d499a",
     "grade": false,
     "grade_id": "cell-4f6e0cdab70cef94",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "If you inspect this file you will find that it has column names, which are strings, and numerical data.  So, numpy will complain that strings cannot be converted to numerical values.  The issue is that numpy arrays are tables of values, all of which must be the same data type.  What this error message is telling you, therefore, is that you are attempting to load a table with two different data types: in this case, strings and numbers. \n",
    "\n",
    "What should you do?  One option is to open up a text editor and remove the column names.  But removing these names would require you, rather than the machine, to keep track of the column labels.  That isn't a very good option, particularly when you haven't even inspected the data.  And trouble compounds with larger datasets.\n",
    "\n",
    "Fortunately there is a Python package, called <b>pandas</b>, designed to work with this particular kind of \"mixed-type\" rectangular data structure.  Specifically, a <b>data frame</b> is a two-dimensional, labeled dataset. Data frames are ubiquitous, since most data includes labels of some kind to describe each feature (column) and, sometimes, each example (row).  A lot of financial data is in this format, too, particularly <b>time series</b> data.  The pandas library offers a very powerful toolkit for working with dataframes.  \n",
    "\n",
    "A better solution to our problem  then is to load our `ps2_data-1.csv` into a pandas dataframe. The following line of code does this,\n",
    "\n",
    "~~~python\n",
    "df = pd.read_csv('ps2_data-1.csv')\n",
    "~~~\n",
    "\n",
    "where `df` is a common naming convention for variables storing dataframes. To inspect `df`, you may type `df.head(5)` to return the labels and first 5 examples:\n",
    "\n",
    "\n",
    "<img src=\"ps2_fig01.png\" alt=\"machine learning i\" style=\"width: 210px;\"/></br>\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "53038baf14839de925ea9d0a2160dd71",
     "grade": false,
     "grade_id": "cell-ec6a0063770bec91",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Now that we can see our data frame, we discover that it is not quite arranged the way we would like.  First, the column labels need to be changed to reflect the category of the taget variable and the correct names of the two features.  That is, you need to\n",
    "\n",
    "~~~python\n",
    "change: 'label' to 'Insolvency'\n",
    "        'x1' to 'ROE'\n",
    "        'x2' to 'Current_Ratio'\n",
    "~~~\n",
    "\n",
    "Note the underscore in the string 'Current_Ratio'. This is important to allow all key valuse to be indexed later.\n",
    "\n",
    "The second change that is necessary is to move the target vector, the `Insolvency` column, to the end of the dataframe.  The result of these changes should be such that `df.head(5)` returns a dataframe that looks exactly like this:\n",
    "      \n",
    "<img src=\"ps2_fig02.png\" alt=\"machine learning i\" style=\"width: 250px;\"/></br>\n",
    "\n",
    "<b>Your task:</b>\n",
    "\n",
    "In the next cell is a partially completed function, `config_df()`, within which you should include a few short lines of code to perform these changes. (By a few, I mean less than 6). When `config_df()` is called, the file `ps2_data-1.csv` is loaded and assigned to `df`. This dataframe is then changed according to the specifications above. When finished, a series of test cells will check that you've done this correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "56041ef76bc8c05cc6ef75cec9e10342",
     "grade": false,
     "grade_id": "reconfig_df",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def config_df():\n",
    "    \"\"\"\n",
    "        config_df() is a function to specifically load \n",
    "        and reconfigure the dataset for this assignment.\n",
    "        \n",
    "        The function takes no argument, but will load the\n",
    "        data file and reconfigure it each time it is run.\n",
    "        \n",
    "        The output should be a pandas dataframe assigned to\n",
    "        the variable 'df'\n",
    "    \"\"\"\n",
    "    # load original dataset\n",
    "    df = pd.read_csv('ps2_data-1.csv')\n",
    "    # YOUR CODE HERE\n",
    "    df = df.rename(columns={'label':'Insolvent', 'x1' : 'ROE','x2':'Current_Ratio'})\n",
    "    df = df[['ROE','Current_Ratio','Insolvent']]\n",
    "    #raise NotImplementedError()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6117223444ada48ca4114e4a464d4361",
     "grade": true,
     "grade_id": "reconfig_df-test-1",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Public Test Cell\n",
    "# call config_df()\n",
    "df = config_df()\n",
    "# Test whether 'Insolvent' heading was moved to the last column\n",
    "assert df.columns[2] == 'Insolvent'\n",
    "# Additional tests are hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7303ab08fc935d23bd2f8a466c74d664",
     "grade": true,
     "grade_id": "reconfig_df-test-2",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4f15385ba6afb2f2aa72f7ea6e40dc07",
     "grade": true,
     "grade_id": "reconfig_df-test-3",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b5f69d4c02d02fa42169401c18ef8f2b",
     "grade": true,
     "grade_id": "reconfig_df-test-4",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fe27a4ee69e775798b64a4a5ec1bd3ed",
     "grade": false,
     "grade_id": "cell-ae27ebfee09138f9",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Dataframes and arrays\n",
    "Some operations are easier on arrays, others on dataframes.  Therefore it can be helpful to pull the table values out of a dataframe and save them as a numpy array. Indeed, for this assignment, it may turn out to be a bit easier to work with arrays.  In any case, the point is to feel comfortable switching when <i>you</i> think it might be easier.   \n",
    "\n",
    "This line\n",
    "\n",
    "~~~python~~~\n",
    "data = df.values\n",
    "~~~\n",
    "creates a numpy array.  Using this hint, complete the next function to extract a $(m \\times n-1)$-features matrix `X` and a target vector `y` from an $n$-column dataframe.  Note that your function should work for data frames that have other than $(n -1) = 2$ features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a562a17e18acdf2cd9812f3f20d995e2",
     "grade": false,
     "grade_id": "array_maker",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def array_maker(df):\n",
    "    \"\"\"\n",
    "       The function array_maker takes an n-column dataframe \n",
    "       df, with m rows, and returns:\n",
    "        \n",
    "         X, a (m x n-1) feature matrix\n",
    "         y, a column vector\n",
    "       \n",
    "       You should assume that the dataframe is arranged where the last\n",
    "       column is the target variable, y.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    df1 = df[['ROE','Current_Ratio']]\n",
    "    df2 = df['Insolvent']\n",
    "    X = df1.values\n",
    "    y = df2.values\n",
    "    #raise NotImplementedError()\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "beb784d9ed052f30db784d8012c7ea81",
     "grade": true,
     "grade_id": "array_maker-test-1",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Public Test Cell\n",
    "# call array_maker()\n",
    "X, y = array_maker(df)\n",
    "assert y[37] == 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b39f143838d92a00818c7013951a4447",
     "grade": true,
     "grade_id": "array-maker-test-2",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "43657304d2fb1c2cbafb46f013864f8e",
     "grade": false,
     "grade_id": "cell-0338db0af92b7228",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## II. Data Visualization\n",
    "\n",
    "The following block of code produces a basic scatterplot with a legend that codes which firms in the data set are insolvent and which are solvent.\n",
    "\n",
    "~~~python\n",
    "mask = y.flatten() == 1\n",
    "insolv = plt.scatter(X[mask][:,0], X[mask][:,1])\n",
    "solv = plt.scatter(X[~mask][:,0], X[~mask][:,1])\n",
    "plt.ylim(-7, 11) \n",
    "plt.xlabel('ROE')\n",
    "plt.ylabel('Current_Ratio')\n",
    "plt.legend((insolv, solv), ('Insolvent', 'Solvent'))\n",
    "plt.show()\n",
    "~~~\n",
    "\n",
    "If you inspect `mask`, you will see that it is an np.array of [Booleans](https://docs.python.org/3/library/stdtypes.html), which is a data type we haven't used yet. What this line does is convert the 0s and 1s in the target vector `y` to `False` and `True`, respectively.  Then, `mask`, the stored array of the Boolean encodings of the class labels, is used as a key to find all of the insolvent ($y =1$) firms in our data set, and `~mask` (where `~` acts as logical negation and flips all the truth values in `mask`) is used to pick out all of the solvent firms.  `Legend` then takes the saved keys, `insolv` and `solv`, and associates with each the labels 'Insolvent' and 'Solvent'. The color scheme is chosen by default, but naturally you could control that, too.\n",
    "\n",
    "The following block is reserved for you to run this code for you to inspect the data visually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1cc7ea6d62a4e333f19b1147fca0c819",
     "grade": true,
     "grade_id": "scatter-plot",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask = y.flatten() == 1\n",
    "insolv = plt.scatter(X[mask][:,0], X[mask][:,1])\n",
    "solv = plt.scatter(X[~mask][:,0], X[~mask][:,1])\n",
    "plt.ylim(-7, 11) \n",
    "plt.xlabel('ROE')\n",
    "plt.ylabel('Current_Ratio')\n",
    "plt.legend((insolv, solv), ('Insolvent', 'Solvent'))\n",
    "plt.show()\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0013b77ad6ab752ac177759ed4e5d1b3",
     "grade": false,
     "grade_id": "cell-0db01e0d772abfd6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## III. Building a Logistic Regression Model\n",
    "\n",
    "We turn now to construct a logistic regression classifier.  One goal of this exercise is to draw attention to the differences between the hypothesis and cost function for logistic regression and the hypothesis and cost function of linear regression, yet to see that both learning algorithms follow the basic logic.  \n",
    "\n",
    "\n",
    "###  Sigmoid Function\n",
    "\n",
    "Recall that the <i>form</i> of the hypothesis $h_\\theta(x)$ for logistic regression is\n",
    "\n",
    "$$h_\\theta(x) = g(\\theta^Tx)$$\n",
    "  \n",
    "where the function $g$ is the <b>sigmoid function</b>:\n",
    "\n",
    "$$g(z) = \\frac{1}{1+e^{-z}}$$\n",
    "\n",
    "Next, using the `np.exp()` function from numpy, implement the sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "68de95694c750e6ab85eac546b20ec35",
     "grade": false,
     "grade_id": "sigmoid-fn",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"implementation of the sigmoid function,\n",
    "    which takes input z, a positive or negative \n",
    "    real number, and returns a value between \n",
    "    0 and 1.\n",
    "    \n",
    "    Your one line of code should be of \n",
    "    the form:  gz = ---\n",
    "    \n",
    "    \"\"\"\n",
    "    # complete sigmoid with one line:\n",
    "    #\n",
    "    # gz = ----\n",
    "    #\n",
    "    # YOUR CODE HERE\n",
    "    gz = 1 / (1 + np.exp(-z))\n",
    "    #raise NotImplementedError()\n",
    "    return gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f5927c3973f6400c3badbccafbddcc0e",
     "grade": true,
     "grade_id": "sigmoid-fn-test",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Public Test \n",
    "assert sigmoid(0) == 0.5\n",
    "assert round(sigmoid(.5),5) == 0.62246"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "de49406dfe4571155b771a28977fa555",
     "grade": false,
     "grade_id": "cell-feb12437df9cd1ff",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "In addition to the public test cell above, you might like to plot your sigmoid function.  Use the [numpy.linspace](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linspace.html) function to construct a sample `xx` of 100 evenly spaced numbers between -10 and 10 to feed to your sigmoid function. This can be done easily with the following few lines:\n",
    "\n",
    "~~~python\n",
    "xx = np.linspace(-10,10,100)\n",
    "plt.plot(xx, sigmoid(xx))\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel(r'$g(x)$')\n",
    "plt.grid(True)\n",
    "~~~\n",
    "\n",
    "Constructing this plot is optional. But, it should look something like this:\n",
    "\n",
    "<img src=\"ps2_fig03.png\" alt=\"Scatter Plot\" style=\"width: 400px;\"/>\n",
    "\n",
    "The color and style of your plot might be slightly different.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f1307f0f4d5bb5f5a25c5890214495a1",
     "grade": false,
     "grade_id": "cell-b3e663a553fef999",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 1\n",
    "\n",
    "Suppose you have trained a logistic regression classifier on data $X$ and it outputs on a new example $x$, which is not in your training data $X$, a prediction that $h_{\\theta}(x) = 0.25$. \n",
    "\n",
    "Identify the true statement(s): \n",
    "\n",
    "<ul>\n",
    " <li>A) According to your classifier, $p(y = 0 \\mid x, \\theta) = 0.25$ </li>\n",
    " <li>B) According to your classifier, $p(y = 0 \\mid x, \\theta) = 0.75$  </li> \n",
    " <li>C) According to your classifier, $p(x = 1 \\mid y, \\theta) = 0.25$</li>\n",
    " <li>D) According to your classifier, $p(x = 1 \\mid y, \\theta) = 0.75$</li>\n",
    " <li>E) None of the above are true</li>\n",
    "</ul>\n",
    "Complete the next function with a list recording your answer(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8e20717763e6898e6858baefd72102d7",
     "grade": false,
     "grade_id": "Question-1",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def ans_one():\n",
    "    # # To answer, set the variable\n",
    "    #\n",
    "    # ans = ---\n",
    "    #\n",
    "    # to a LIST which is a sublist of\n",
    "    # the possible answers: ['A', 'B', 'C', 'D', 'E'].\n",
    "    #\n",
    "    # YOUR CODE HERE\n",
    "    ans = ['B']\n",
    "    #raise NotImplementedError()\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2d9af76b2a2edbd4d9ce6390c3a46da0",
     "grade": true,
     "grade_id": "Question-1-test",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Test cell to check the format of your answer\n",
    "ans = ans_one()\n",
    "possible_ans = ['A', 'B', 'C', 'D', 'E']\n",
    "if type(ans) == list and all(ii in possible_ans for ii in ans):\n",
    "    assert True\n",
    "else:\n",
    "    raise AssertionError(\"Inadmissible answer. Check that your answer is the correct format.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "de91c3817eaa03326ca4802d10343481",
     "grade": false,
     "grade_id": "cell-80b6aaa6e6942d0b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Cost Function J$(\\theta)$\n",
    "The cost function for logistic regression is\n",
    "\n",
    "$$J(\\theta) = \\frac{1}{m}\\sum_{i=1}^{m} \\left(-y^{(i)} \\log\\left[h(x^{(i)}, \\boldsymbol{\\theta})\\right] - (1- y^{(i)}) \\log\\left[1- h(x^{(i)}, \\boldsymbol{\\theta}) \\right]\\right)$$\n",
    "\n",
    "which can be rewritten as\n",
    "\n",
    "$$J(\\theta) = - \\frac{1}{m} \\left(\\sum_{i=1}^{m} y^{(i)} \\log\\left[  h(x^{(i)}, \\boldsymbol{\\theta}) \\right] + (1- y^{(i)}) \\log\\left[1- h(x^{(i)}, \\boldsymbol{\\theta}) \\right] \\right)$$\n",
    "\n",
    "The gradient of this cost function is a vector which is the same length $n$ as $\\theta$, where the $j$th element (for $j = 0,1,2,\\ldots,n)$ is\n",
    "\n",
    "$$ \\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\frac{1}{m} \\sum_{i = 1}^{m} \\left( h(x^{(i)}, \\boldsymbol{\\theta}) - y^{(i)}  \\right) x^{(i)}_j$$\n",
    " \n",
    "\n",
    "---\n",
    "\n",
    "## Question 2\n",
    "\n",
    "Compare logistic regression to linear regression. Identify the true statement(s).\n",
    "\n",
    "<ul>\n",
    " <li>A) The gradients are identical and the hypotheses are the same. </li>\n",
    " <li>B) The gradients are identical and the hypotheses are not the same.  </li>\n",
    " <li>C) The gradients are not identical and the hypotheses are the same. </li>\n",
    " <li>D) The gradients are not identical and the hypotheses are not the same.</li>\n",
    " <li>E) There is insufficient information to answer. </li>\n",
    "</ul>\n",
    "\n",
    "Complete the next function with a list of your answer(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5192f785ba8afdeada557f1f3d941037",
     "grade": false,
     "grade_id": "multi-gradient-ans",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def ans_two():\n",
    "   # # To answer, set the variable\n",
    "    #\n",
    "    # ans = ---\n",
    "    #\n",
    "    # to a LIST which is a sublist of\n",
    "    # the possible answers: ['A', 'B', 'C', 'D', 'E'].\n",
    "    #\n",
    "    # YOUR CODE HERE\n",
    "    ans = ['B']\n",
    "    #raise NotImplementedError()\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7353c7bec18abf9efbed65514516b756",
     "grade": true,
     "grade_id": "multi-gradient-test",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Test cell to check the format of your answer\n",
    "ans = ans_two()\n",
    "possible_ans = ['A', 'B', 'C', 'D', 'E']\n",
    "if type(ans) == list and all(ii in possible_ans for ii in ans):\n",
    "    assert True\n",
    "else:\n",
    "    raise AssertionError(\"Inadmissible answer. Check that your answer is the correct format.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9ad1b1ec807e4eff31fe49c340167c00",
     "grade": false,
     "grade_id": "cell-23acdc40307e567a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Implementation\n",
    "\n",
    "The next step is to implement the cost function and compute the gradient for logistic regression.  This implementation  will use `sigmoid()`, which you implemented above. \n",
    "\n",
    "\n",
    "There are four steps to implementing `costFunction()`: \n",
    "\n",
    "<ol>\n",
    "    <li>Compute the hypothesis: $h(x; \\boldsymbol{\\theta}) = g(\\theta^Tx)$ </li>\n",
    "    <li>Compute the Cost Function: $J(\\theta) = - \\frac{1}{m} \\left(\\sum_{i=1}^{m} y^{(i)} \\log\\left[  h(x^{(i)}, \\boldsymbol{\\theta}) \\right] + (1- y^{(i)}) \\log\\left[1- h(x^{(i)}, \\boldsymbol{\\theta}) \\right] \\right)$\n",
    "    <li>Compute the gradients: $ \\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\frac{1}{m} \\sum_{i = 1}^{m} \\left( h(x^{(i)}, \\boldsymbol{\\theta}) - y^{(i)}  \\right) x^{(i)}_j$\n",
    "    <li> Using the implementations from parts 2 and 3, implement the final, executable cost function, `costFunction()`, which returns the cost, `J`, and gradiate, `grad`.\n",
    "</ol>\n",
    "\n",
    "The first function for you to complete, `computeJ()`, will require you to compute the hypothesis (step 1) and plug that value into the cost function (step 2) in order to return a value for $J$. With a working cost function, we can compute the gradient (step 3).  Then, with a working gradient function `computeGradient()`, implements the executable cost function, `costFunction()`, that we will pass to our optimization algorithm. \n",
    "\n",
    "---\n",
    "Let's turn now to the implementation.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Vectorize your code:</b> You will not receive full credit unless you vectorize your code. Specifically, you should not use any for loops or while statements.     \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e4b04b41c43e862413fc6adb604c266e",
     "grade": false,
     "grade_id": "cell-d562c5418f82b7a4",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### Step 1. Computing the cost function\n",
    "The function `computeJ()` computes the cost function $J$ for a specific parameter vector $\\boldsymbol{\\theta}$. Recall from the matrix multiplication tutorial that `X @ theta` is equivalent to `np.dot(X, theta)`. This can allow for a fairly direct representation of the cost function using \n",
    "\n",
    "- `np.sum`\n",
    "- `np.multiply`\n",
    "- `np.log`\n",
    "- `sigmoid`, which you defined above,\n",
    "-  the variables `X`, `y`, `m`, and `theta`,\n",
    "-  `-`, `+`, and `*`, \n",
    "\n",
    "and the normalizing term, $-\\frac{1}{m}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2b74497800cafc13ba3967f8ec81e6d4",
     "grade": false,
     "grade_id": "computeCostFunc-ans",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def computeJ(theta, X, y):\n",
    "    \"\"\"\n",
    "        computeCostFunction() computes the cost function\n",
    "        J for logistic regression.\n",
    "        \n",
    "        You can complete this function with one line of code:\n",
    "        \n",
    "        J = ---\n",
    "    \"\"\"\n",
    "    # number of training samples\n",
    "    # DO NOT CHANGE\n",
    "    m = len(y)  \n",
    "    # YOUR CODE HERE  \n",
    "    #J = np.sum(np.log(sigmoid(np.dot(X,theta)))*y + np.log(1-sigmoid(np.dot(X,theta)))*(1-y))*(-1/m)\n",
    "    J = np.sum(np.log(sigmoid(np.dot(X,theta)))*y + np.log(1-sigmoid(np.dot(X,theta)))*(1-y))*(-1/m)\n",
    "    #print(J)\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "77dfce2b431f1217d09404cde1a7c84f",
     "grade": true,
     "grade_id": "computeCostFunc-test1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Public Test\n",
    "theta_t = np.array([.02,.01])\n",
    "assert round(computeJ(theta_t, X, y), 5) == 0.72982"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "72c97b18afb1a1282a7c8db7f3a48d0c",
     "grade": true,
     "grade_id": "computeCostFunc-test4-TIME",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5844521ad96792f95bf94f3994fb2d3a",
     "grade": false,
     "grade_id": "cell-86411ce2c3c2584f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### Step 2. Compute the gradient\n",
    "Now compute the gradient, using\n",
    "\n",
    "- `X.T` (X transposed)\n",
    "- `np.dot` or `@`\n",
    "- `sigmoid`\n",
    "- the variables `X`, `theta`, `y`, and `m`\n",
    "- the operators `*` and `-`\n",
    "\n",
    "and the normalizing term $\\frac{1}{m}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b655766ab98f3a4bf92c5ce25cc46558",
     "grade": false,
     "grade_id": "computeGradient-ans",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def computeGradient(theta, X, y):\n",
    "    \"\"\"\n",
    "        computeGradient() computes the gradient\n",
    "        grad for logistic regression\"\"\"\n",
    "    # number of training samples\n",
    "    m = len(y)\n",
    "    \n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    grad = (1/m)*(np.dot(sigmoid(np.dot(X,theta))-y,X))\n",
    "    #raise NotImplementedError()\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2847831deec866f2cc682ab8729ab23d",
     "grade": true,
     "grade_id": "computeGradient-test1",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a0ab845d9e2b197eac3c4f3e66825325",
     "grade": false,
     "grade_id": "cell-dd2272151d00abb6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### Step 3. Implement the executable cost function\n",
    "\n",
    "The complete implementation of the cost function, `costFunction()`, is already written for you:\n",
    "\n",
    "~~~python\n",
    "def costFunction(theta, X, y):\n",
    "    \"\"\"Executable cost function\"\"\"\n",
    "    # use cost function\n",
    "    J = computeJ(theta, X, y)\n",
    "    \n",
    "    # use gradient function\n",
    "    grad = computeGradient(theta, X, y)\n",
    "    \n",
    "    return J, grad\n",
    "~~~\n",
    "\n",
    "Run the next cell to make this function available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costFunction(theta, X, y):\n",
    "    \"\"\"Executable cost function\"\"\"\n",
    "    # use cost function\n",
    "    J = computeJ(theta, X, y)\n",
    "    \n",
    "    # use gradient function\n",
    "    grad = computeGradient(theta, X, y)\n",
    "    \n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f9349addbddd9b665d2a87eefc3e84ce",
     "grade": false,
     "grade_id": "cell-2729817da3d67b53",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Computing initial theta \n",
    "\n",
    "If you implemented `computeJ()` and `computeGradient()` correctly, then running the next block of code should return an initial cost, when theta is initialized to an array of zeros, of approximately $0.6931$, and the gradient vector at this initialized theta is a three element array, with approximate values of $[0.001 \\ 1.318 \\ 0.932 ]$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at initial theta (zeros): 0.6931471805599454\n",
      "Gradient at inital theta (zeros): [0.00141643 1.31783649 0.93191404]\n"
     ]
    }
   ],
   "source": [
    "## DO NOT EDIT\n",
    "#\n",
    "# setup the data matrix appropriately\n",
    "m, n = X.shape\n",
    "\n",
    "# add intercept term to X\n",
    "X = np.hstack((np.ones((m, 1)), X))\n",
    "\n",
    "# initalize theta\n",
    "initial_theta = np.zeros(n+1)\n",
    "\n",
    "# compute and display initial cost and gradient\n",
    "J, grad = costFunction(initial_theta, X, y)\n",
    "\n",
    "# print cost J at initialization\n",
    "print('Cost at initial theta (zeros): {0}'.format(J))\n",
    "# print gradiate at initialization\n",
    "print('Gradient at inital theta (zeros): {0}'.format(grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0f1ef045cf2e60cee985e97b057848d3",
     "grade": false,
     "grade_id": "cell-bafbe61956f9e8f6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> You will have touched stored variables several times by now, so if you have run cells out of order (which is not unusual) you may see unexpected values or even errors.  For example, the code block above adds a column of 1s to X. Running that cell more than once will keep adding columns of ones to your features matrix X, changing its dimension. A good rule of thumb, if you cannot see immediately what problem an error message is telling you, is to select <b>Cell >> All Outputs >> Clear </b> from the menu, then run all cells <b>once</b> in sequence from the beginning.   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f0f39953ee925bc006f518f0203215bd",
     "grade": true,
     "grade_id": "compute-initial-theta-test",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Tests of J and the three elements of grad\n",
    "# approximate cost J with zeros initial_theta\n",
    "assert round(J,4) == 0.6931\n",
    "# approximate gradient grad with zeros initial_theta\n",
    "#   grad[0]\n",
    "assert round(grad[0],3) == 0.001 \n",
    "#   grad[1]\n",
    "assert round(grad[1],3) == 1.318\n",
    "#   grad[2]\n",
    "assert round(grad[2],3) == 0.932"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Learning parameters\n",
    "\n",
    "In <b>problem set 1 (ps1) </b> we implemented <b>batch gradient descent</b> to learn the optimal parameters $\\boldsymbol{\\theta} = (\\theta_0, \\theta_1)$ that minimized the cost function $J(\\boldsymbol{\\theta})$, yielding the best fitting linear model which minimized <b>mean-squared error</b> (MSE).  That exercise was intended to help further develop your intuitions about <i>how</i> computational optimization techniques are used to perform supervised learning, and how to change hyperparameters to get better performance.  \n",
    "\n",
    "Instead of re-using your gradient descent algorithm, you instead will use a powerful built-in optimization algorithm called BFGS. The <b>Broyden–Fletcher–Goldfarb–Shanno</b> algorithm, or [BFGS algorithm](https://en.wikipedia.org/wiki/Broyden%E2%80%93Fletcher%E2%80%93Goldfarb%E2%80%93Shanno_algorithm), is a numerical optimization method for solving <i>non-linear</i> optimization problems.  (It won't matter that our classifier is a general linear model.)  \n",
    "\n",
    "\n",
    "We will use the scipy implementation of BFGS from the [scipy.optimize](https://docs.scipy.org/doc/scipy/reference/tutorial/optimize.html) package, which will compute values for the parameter vector $\\boldsymbol{\\theta}$ that minimize the cost function $J$.  The block of code below imports `fin_bfgs` and saves to the output of the BFGS optimizer to `theta_opt`.\n",
    "\n",
    "~~~python\n",
    "from scipy.optimize import fmin_bfgs\n",
    "theta_opt = fmin_bfgs(computeJ, initial_theta, fprime=computeGradient,\n",
    "                maxiter=100, args=(X,y), disp=True)\n",
    "~~~    \n",
    "where:\n",
    "- `computeJ` is the objective function to be minimized</li>\n",
    "- `initial_theta` is the initialized parameter vector from part e)</li>\n",
    "- `fprime=computeGradient` is the option to compute the gradient, using your computeGradient function </li>\n",
    "- `maxiter=100` is the maximum number of iterations.</li>\n",
    "- `args=(X,y)` supplies the features and target variable.</li>\n",
    "- `disp=True` prints information about convergence and successful termination if true; otherwise, prints a warning message.\n",
    "\n",
    "See the online [documentation](https://docs.scipy.org/doc/scipy-0.19.0/reference/generated/scipy.optimize.fmin_bfgs.html) page or the class lecture notes for more information.\n",
    "\n",
    "Use the next cell to compute the optimized theta values `theta_opt`. If your cost function `computeJ` and gradient function `computeGradient` are implemented correctly, the BFGS algorithm should successfully terminate in approximately 15 iterations and print a value of approximately $0.210$.  This is the value of the objective function `computeJ()` parameterized by `theta_opt` with `X` and `y` as arguments.  Put differently, if your cost and gradient functions are implemented correctly, you should expect `computeJ(theta_opt, X, y)` $\\approx 0.210$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49ca2cdbc33597ed233e5418111ae5dd",
     "grade": true,
     "grade_id": "BFGS-ans",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.210453\n",
      "         Iterations: 14\n",
      "         Function evaluations: 15\n",
      "         Gradient evaluations: 15\n"
     ]
    }
   ],
   "source": [
    "# Compute optimal parameter vector \n",
    "# theta_opt using BFGS\n",
    "\n",
    "from scipy.optimize import fmin_bfgs\n",
    "theta_opt = fmin_bfgs(computeJ, initial_theta, fprime=computeGradient,\n",
    "                maxiter=100, args=(X,y), disp=True)\n",
    "\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fab72e8e38929e3f3146e801bb05efd7",
     "grade": true,
     "grade_id": "BFGS-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Test of computeCostFunction(theta_new, X, y) using the opitimal \n",
    "# parameters theta_new\n",
    "#\n",
    "assert round(computeJ(theta_opt, X, y),5) == 0.21045"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot decision boundary\n",
    "\n",
    "Above we produced a scatter plot of the data. That code can be slightly adapted to plot a decision boundary. The following two lines of code plots the decision boundary, which here is calculated with a default probability of 1/2.  This line of code\n",
    "\n",
    "~~~python\n",
    "plot_x = [-10, 8]\n",
    "plot_y = -1/theta_opt[2]*(theta_opt[0] \n",
    "          + np.dot(theta_opt[1],plot_x))\n",
    "~~~\n",
    "where you might notice that nowhere does the data, `X`, figure <i>directly</i> in the computation of the decision boundary. It is a function of the parameter vector `theta_opt`.  Data is used to compute the parameter vector `theta_opt`, of course, but the data is not used to compute the decision boundary.  \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Hint:</b> The dimension of $X$ is now different from your first scatter plot above.   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dd08a8dad9cb1a7fec54263af6394d48",
     "grade": true,
     "grade_id": "decision-boundary",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Decision Boundary\n",
    "# YOUR CODE HERE\n",
    "\n",
    "insolv = plt.scatter(X[mask][:,1], X[mask][:,2])\n",
    "solv = plt.scatter(X[~mask][:,1], X[~mask][:,2])\n",
    "plot_x = [-10, 8]\n",
    "plot_y = -1/theta_opt[2]*(theta_opt[0] \n",
    "          + np.dot(theta_opt[1],plot_x))\n",
    "plt.ylim(-7, 11) \n",
    "plt.xlabel('ROE')\n",
    "plt.ylabel('Current_Ratio')\n",
    "plt.legend((insolv, solv), ('Insolvent', 'Solvent'))\n",
    "plt.plot(plot_x,plot_y)\n",
    "#plt.plot(X,y)\n",
    "plt.show()\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Using the model\n",
    "\n",
    "Now suppose you wish to predict whether a particular firm which has an ROE of 0.0 and a current ratio of 0.0 is more likely or not to be insolvent. According to your model, what is the probability that it is insolvent?\n",
    "\n",
    "Complete the following function to compute an answer.  Your one line of code should be of the form\n",
    "\n",
    "~~~python\n",
    "prob = ---(---(---, ---))\n",
    "~~~\n",
    "\n",
    "If implemented correctly, For ROE of 0.0, Current ratio of 0.0, and parameters `theta_opt` that you have already calculated using `fmin_bfgs` with respect to your features $X$ and correct labels $y$, the probability of insolvency for such a firm should be approximately $0.4$.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Hint:</b> The function templates you have worked up until now have used the same variable names as global variables that you have been using, but this convention is about to change.  This convention was helpful to get us started to see how these various pieces are put together. But, unfortunately, this convention comes with a cost, since our functions are general: they do not and <b> should not hard-code variables </b> from outside the function call.  For example, <b>costFunction(theta, X, y)</b> takes as arguments three <b>variables</b>. In practice, you can call <b>costFunction(duck, Xman, why)</b>, where 'duck' is substituted inside the function for 'theta', 'Xman' for 'X', and 'why' for 'y'. Assuming these variables are of the right type, the algorithm will run.  A mistake that can happen is to hard code our X into a function, rather than using whatever is called in the X position.\n",
    "\n",
    "This might not make sense until you run into an error. However, you may run into an error involving <b>theta</b> now that we have computed <b>theta_opt</b>.   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0fdf05f6522fdd798cb3641e1cdcd56a",
     "grade": false,
     "grade_id": "probOfAcceptance-ans",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def probabilityInsolvent(score1, score2, theta):\n",
    "    \"\"\"\n",
    "        probabilityInsolvent calculates the probability that a\n",
    "        firm is insolvent based on two indicators:\n",
    "        \n",
    "          score1, which in our model is the ROE score;\n",
    "          score2, which in our model is the Current Ratio;\n",
    "        \n",
    "        according to the logistic regression model parameterized by \n",
    "        \n",
    "          theta, the fitted parameter vector\n",
    "          \n",
    "        and the features matrix X and labeled category vector y.\n",
    " \n",
    "    \"\"\"\n",
    "    #construct a 1 x 2 array from score1 and score2\n",
    "    #print(score1)\n",
    "    #print(score2)\n",
    "    scores = np.array([score1, score2])\n",
    "    #C\n",
    "    # add a 1 to the front of scores, yielding \n",
    "    # a 1 x 3 array\n",
    "    scores = np.hstack((np.array([1]), scores))\n",
    "    #print(scores)\n",
    "    # calculate the probability (1 line)\n",
    "    # prob = ---\n",
    "    #\n",
    "    # YOUR CODE HERE\n",
    "    #print(np.dot(scores,theta))\n",
    "    prob = sigmoid(np.dot(scores,theta))\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3971584898269461"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the student's probability of acceptance\n",
    "probabilityInsolvent(0.0, 0.0, theta_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8e1ed3e9d1f55d4ab4b7816eaabe5866",
     "grade": true,
     "grade_id": "probOfAcceptance-test",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. Evaluating the model\n",
    "We can see from the plot of the decision boundary that our model is not completely accurate: there are some firms that we know are insolvent but which the model predicts are solvent and vice versa.  But how accurate is the model overall?\n",
    "\n",
    "To answer this question, we first define a `predictionAccuracy` function to predict values of $y$ given the values computed for $h_\\theta(x)$ by our logistic regression model.  This is done for you in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Accuracy of your Model\n",
    "# DO NOT EDIT \n",
    "def predictAccuracy(X, y, theta):\n",
    "    pred = [sigmoid(np.dot(X, theta)) >= 0.5]\n",
    "    acc = np.mean(pred == y)   \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9178470254957507"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#theta_opt\n",
    "predictAccuracy(X,y,theta_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now apply `predictAccuracy` to get the accuracy of your optimized logistic regression model on the training data.  If implemented correctly, the training accuracy should be approximately $0.918$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fe86325d7ea8700c7979b6aa3fce806d",
     "grade": true,
     "grade_id": "training_accuracy_test",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Public Test\n",
    "assert len(theta_opt) == 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VII. Changing the decision threshold\n",
    "\n",
    "The decision boundary we plotted above and the probabilities that we calculated for insolvency ($y = 1$) where keyed to a probability <b>threshold</b> of 1/2.  Recall that this threshold corresponds to when $z = 0$ for `sigmoid(z)`, which yields the probability $p(y =1) = g(0) = \\frac{1}{2}$. \n",
    "\n",
    "The next graph depicts a $g(z) = \\frac{1}{2}$ threshold as a function of $z =0$, plotted in red. Recall that negative values of $z$ correspond to probability estimates that the negative ($ y = 0$) class is more likely than the than positive class $(y = 1$), positive values of $z$ correspond to estimates that the positive class ($y =1$) is more likely than the negative class ($y = 0$), and $z=0$, the corner case of even-odds that the class is positive or negative, is by convention included with the more-likely-than-not predictions that the class is positive ($y =1$).  \n",
    "\n",
    "\n",
    "\n",
    "<img src=\"ps2_fig04a.png\" alt=\"Scatter Plot\" style=\"width: 300px;\"/> \n",
    "\n",
    "Suppose we wish to have a higher probability of acceptance than 1/2, specifically $p(y =1) = 0.7$.  As a function of $z$, this would entail moving the threshold to the right:\n",
    "<img src=\"ps2_fig04b.png\" alt=\"Scatter Plot\" style=\"width: 300px;\"/>\n",
    "\n",
    "Your task is to (i) plot a <b> new decision boundary</b> and (ii) find a threshold probability that <b>maximizes</b> the accuracy score computed by `np.mean(pred ==y)`, where `pred` predicts whether $y = 1$ or $y = 0$ depending on the the probability threshold for acceptance, which can range from 0 to 1.\n",
    "\n",
    "### Step 1. New Decision Boundary\n",
    "Use the next cell to compute and plot a new decision boundary where $p(y =1) = 0.7$ rather than $p(y = 0) = 0.5$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dcc0ac130e074c89e4b02ef74e42ab48",
     "grade": true,
     "grade_id": "decision-boundary-new",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "z = 0\n",
    "gz = 1 / (1 + np.exp(-z + np.log(3/7)))\n",
    "#print(gz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. New Predicted Probability of Insolvency\n",
    "\n",
    "Our accuracy score is approximately $0.918$.  Can we get a higher accuracy score? This is the question we will explore next.\n",
    "\n",
    "There are two functions to finish: (i) `newPredictAccuracy()` computes the accuracy of your model with a given threshold probability value specified by `threshold`; (ii) `maxAcc()` finds the threshold value or values which maximizes the accuracy score computed by `newPredictAccuracy()` and returns two variables: `acc`, which stores the highest accuracy score, and `thresh`, which stores the threshold value or values in an np.array for that highest score. \n",
    "\n",
    "To simplify computations and standardize answers, the <b>precision criterion</b> of tested threshold values is <b>two decimal places</b>.  For example, given the closed interval $[0.49, 0.51]$ the sequence of threshold values from you would use is $(0.49, 0.50, 0.51)$. No other number within $[0.49, 0.51]$ satisfies the precision criterion. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8de048ece298569a0ad73993155342b8",
     "grade": false,
     "grade_id": "new_predict_acc",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "## complete the function\n",
    "def newPredictAccuracy(X, y, theta, threshold=0.5):\n",
    "    # YOUR CODE HERE\n",
    "    pred = [sigmoid(np.dot(X, theta)) >= threshold]\n",
    "    acc = np.mean(pred == y)\n",
    "    #raise NotImplementedError()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cbee1e0dc05152792be441a65ca5f665",
     "grade": true,
     "grade_id": "new_predict_acc-test",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08a9ac4f56f0b097012c6036496f26dc",
     "grade": false,
     "grade_id": "maxACC",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "## complete the function\n",
    "def maxAcc(X,y,theta):\n",
    "    # YOUR CODE HERE\n",
    "    acc_list = []\n",
    "    for i in np.arange (0.00, 1.00, 0.01):\n",
    "        all_thresh = i\n",
    "        test_acc = newPredictAccuracy(X, y, theta_opt, all_thresh)\n",
    "        acc_list.append(test_acc)\n",
    "        acc = max(acc_list)\n",
    "        thres_list = [index for index, value in enumerate(acc_list) if value == acc]\n",
    "        thresh = np.array([x / 100 for x in thres_list])\n",
    "    \n",
    "    # raise NotImplementedError()\n",
    "    return ans, thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['B'], array([0.41, 0.42, 0.43]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxAcc(X,y,theta_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "41dc8dec642cc602aaa238864da4981d",
     "grade": true,
     "grade_id": "maxAcc-test-1",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "04e626194f7c1ea6cb2446e7c9a1b927",
     "grade": true,
     "grade_id": "maxAcc-test-2",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3e9dc3e52783169a011be0ead1741dd3",
     "grade": true,
     "grade_id": "maxAcc-test-3",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART B - SciKit-Learn Logistic Regression\n",
    "\n",
    "Naturally, there are built-in libraries for logistic regression classification models.  In fact, it just takes a few lines of code once we import `LogisticRegression` from the `linear_model` methods in the `sklearn` (scikit-learn) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn uses a common [API](https://en.wikipedia.org/wiki/Application_programming_interface) for building models. So, the sequence we follow to build a simple linear model resembles the sequence of steps for building a wide range of models.  It is good, therefore, to become aquainted with this tool.\n",
    "\n",
    "Basically, there are two steps:\n",
    "\n",
    " - Instantiate a model\n",
    "  \n",
    " - Fit the model\n",
    "\n",
    "Followed by plotting and some rudimentary anlysis of the model. Later in the course we will add a third step, which involves making predictions and evaluating the accuracy of those predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 3\n",
    "\n",
    "To answer the next question, you should use a [Sklearn logistic regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) model and methods. It is necessary to use the following (and only the following) parameter settings:\n",
    "\n",
    "~~~python\n",
    "model = LogisticRegression(random_state=21)\n",
    "\n",
    "~~~\n",
    "\n",
    "There are four quantities that you will need to report about your Logistic regression model: \n",
    "\n",
    " - a) The predicted probability that $y=0$ for the first observation in the training set, rounded to 3 decimal places.\n",
    " - b) The predicted class label of the last observation in the training set.\n",
    " - c) True or False: the predicted class label of the last observation in the training set is  correct.  \n",
    "\n",
    "\n",
    "Complete the next function to record your answer(s). Pay attention to data types.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f56698fc1117e363d0bfe77d4d9191ea",
     "grade": false,
     "grade_id": "Question-3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def ans_three():\n",
    "    \"\"\" Returns four numerical values of your linear model.  \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    :a:  float\n",
    "        The predicted probability of the first training example, rounded to 3 decimal places.\n",
    "    :b:  float\n",
    "        The predicted class label of the last observation in the taining set\n",
    "    :c:  Boolean\n",
    "        The truth value of the assertion that the predicted label of the last observation is correct.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    :a:\n",
    "    :b:\n",
    "    :c:\n",
    "    \"\"\"\n",
    " \n",
    "    # YOUR CODE HERE\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    model = LogisticRegression(random_state=21).fit(X, y)\n",
    "    a = model.predict_proba(X[:1, :])[0][0]\n",
    "    b = model.predict(X[-1:,:])[0]\n",
    "    c = (b == y[-1])\n",
    "    #raise NotImplementedError()\n",
    "    return a, b, c # do not edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6206700436260497, 1, False)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_three()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "32484f05fce8a0a4c81715bfd96f2035",
     "grade": true,
     "grade_id": "Question-3-test1",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "24966e1d81aee742e01fbe2457fe025a",
     "grade": true,
     "grade_id": "cell-6fd340c7ecf36e8a",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4a163bc3d4048ed202fbd57daed6c6d7",
     "grade": true,
     "grade_id": "cell-98483df44ebaa642",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "74d9936e7564e6ff345fb45a606c92b1",
     "grade": true,
     "grade_id": "cell-5425d410332fcbb9",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test for Collaborator policy before submission\n",
    "%run -i 'collaboration_test.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a00e150ce7f067aee6e3312b34cca309",
     "grade": false,
     "grade_id": "cell-15ddd442d94aef91",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Before turning this notebook in, you should do the following steps:\n",
    "  \n",
    "  1. __Restart Kernel__ (Kernel ⟶ Restart and Clear Output)\n",
    "  2. __Run all Cells__ (Cell ⟶ Run All)\n",
    "  3. __Validate__: Press the 'Validate' button\n",
    "  4. __Save File__ (File ⟶ Save and Checkpoint)\n",
    "  5. __Close and Shutdown Kernel__ (File ⟶ Close and Halt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
